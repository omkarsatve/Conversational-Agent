{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6212171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "hf_api_key = os.getenv(\"HUGGINGFACE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af483098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGoogleGenerativeAI(model='models/gemini-2.0-flash-lite', google_api_key=SecretStr('**********'), temperature=0.3, top_k=4, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000017D8B7A3A90>, default_metadata=())"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash-lite\",  # or gemini-pro if you want\n",
    "    google_api_key=google_api_key,\n",
    "    temperature=0.3,\n",
    "    top_k=4\n",
    ")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a19026db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=hf_api_key,\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a09de9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x17d8e4dc310>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "vectorstore = FAISS.load_local(\"../vectorstores/dxfactor\", embedding_model, allow_dangerous_deserialization=True)\n",
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e15ef3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "from typing import TypedDict, List, Optional\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Define the structure of the state\n",
    "class ChatState(TypedDict):\n",
    "    question: str\n",
    "    answer: Optional[str]\n",
    "    docs: Optional[List[Document]]\n",
    "    first_turn: bool\n",
    "    chat_history: List  # To hold past conversation turns\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# System prompt\n",
    "system_prompt = SystemMessage(\n",
    "    content=(\n",
    "        \"You are a helpful AI assistant for the DXFactor website. \"\n",
    "        \"Answer questions based on the content scraped from the site. \"\n",
    "        \"You are having a multi-turn conversation, so remember the previous questions and answers. \"\n",
    "        \"If the user asks about something from earlier, use the chat history to respond appropriately. \"\n",
    "        \"Keep your tone professional and helpful.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# LangGraph\n",
    "graph = StateGraph(ChatState)\n",
    "\n",
    "# Node: Get user input\n",
    "def get_user_input(state):\n",
    "    user_input = input(\"\\nUser: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "        print(\"ðŸ‘‹ Exiting chatbot. Have a great day!\")\n",
    "        raise SystemExit  # This prevents recursion loop\n",
    "    state[\"question\"] = user_input\n",
    "    return state\n",
    "\n",
    "# Node: Retrieve documents\n",
    "def retrieve_docs(state):\n",
    "    state[\"docs\"] = retriever.get_relevant_documents(state[\"question\"])\n",
    "    return state\n",
    "\n",
    "def generate_answer(state):\n",
    "    question = state[\"question\"]\n",
    "    docs = state.get(\"docs\", [])\n",
    "\n",
    "    # Build the context from documents\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in docs[:5]) if docs else \"No relevant documents found.\"\n",
    "\n",
    "    # Greeting logic\n",
    "    if state[\"first_turn\"]:\n",
    "        greeting = \"Hi! Welcome to DXFactor â€” how can I help you today?\\n\\n\"\n",
    "        state[\"first_turn\"] = False\n",
    "    else:\n",
    "        greeting = \"\"\n",
    "\n",
    "    # Prepare the message for this turn\n",
    "    user_message = HumanMessage(content=f\"Context:\\n{context}\\n\\nQuestion: {question}\")\n",
    "\n",
    "    # Initialize chat_history if not present\n",
    "    if \"chat_history\" not in state or state[\"chat_history\"] is None:\n",
    "        state[\"chat_history\"] = []\n",
    "\n",
    "    # Combine full message sequence\n",
    "    messages = [system_prompt] + state[\"chat_history\"] + [user_message]\n",
    "\n",
    "    try:\n",
    "        response = llm.invoke(messages)\n",
    "        print(response)\n",
    "        answer = output_parser.invoke(response).strip()\n",
    "        if not answer:\n",
    "            answer = \"I'm sorry, I couldn't find a relevant answer based on the website data.\"\n",
    "    except Exception as e:\n",
    "        answer = f\"An error occurred: {str(e)}\"\n",
    "\n",
    "    # Full response to display\n",
    "    full_response = greeting + answer\n",
    "    print(\"\\nðŸ¤– Gemini:\")\n",
    "    print(full_response)\n",
    "\n",
    "    # Update chat history â€” must be done *before* next round\n",
    "    state[\"chat_history\"].extend([user_message, response])\n",
    "    state[\"answer\"] = answer\n",
    "    return state\n",
    "\n",
    "# Register nodes and flow\n",
    "graph.add_node(\"Input\", get_user_input)\n",
    "graph.add_node(\"Retrieve\", retrieve_docs)\n",
    "graph.add_node(\"Answer\", generate_answer)\n",
    "\n",
    "graph.set_entry_point(\"Input\")\n",
    "graph.add_edge(\"Input\", \"Retrieve\")\n",
    "graph.add_edge(\"Retrieve\", \"Answer\")\n",
    "graph.add_edge(\"Answer\", \"Input\")\n",
    "\n",
    "# Compile chatbot\n",
    "chatbot = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cc5aebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Hello Harish, welcome! How can I help you today?' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-lite', 'safety_ratings': []} id='run-040e37c2-6009-4323-8ef6-2b6a2aca2562-0' usage_metadata={'input_tokens': 1284, 'output_tokens': 14, 'total_tokens': 1298, 'input_token_details': {'cache_read': 0}}\n",
      "\n",
      "ðŸ¤– Gemini:\n",
      "Hi! Welcome to DXFactor â€” how can I help you today?\n",
      "\n",
      "Hello Harish, welcome! How can I help you today?\n",
      "content='DXFactor helps businesses achieve transformational outcomes through Agile Delivery, Data Governance, Cloud Deployment, Data Quality & Management, and Data Analytics.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-lite', 'safety_ratings': []} id='run-09f7d1b5-e229-4a40-9189-10601def1b42-0' usage_metadata={'input_tokens': 1499, 'output_tokens': 28, 'total_tokens': 1527, 'input_token_details': {'cache_read': 0}}\n",
      "\n",
      "ðŸ¤– Gemini:\n",
      "DXFactor helps businesses achieve transformational outcomes through Agile Delivery, Data Governance, Cloud Deployment, Data Quality & Management, and Data Analytics.\n",
      "content='DXFactor helps businesses achieve transformational outcomes through Agile Delivery, Data Governance, Cloud Deployment, Data Quality & Management, and Data Analytics. They focus on delivering measurable and tangible outcomes that drive change across an enterprise.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-lite', 'safety_ratings': []} id='run-7d85ec97-c8be-430c-80f4-a766688518a8-0' usage_metadata={'input_tokens': 2571, 'output_tokens': 43, 'total_tokens': 2614, 'input_token_details': {'cache_read': 0}}\n",
      "\n",
      "ðŸ¤– Gemini:\n",
      "DXFactor helps businesses achieve transformational outcomes through Agile Delivery, Data Governance, Cloud Deployment, Data Quality & Management, and Data Analytics. They focus on delivering measurable and tangible outcomes that drive change across an enterprise.\n",
      "content='I am sorry, I am unable to answer your question based on the provided context. The context does not contain information about any specific event. Is there anything else I can help you with?' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-lite', 'safety_ratings': []} id='run-08ce33f8-3376-45fd-8fa1-cfbc9e3377d9-0' usage_metadata={'input_tokens': 3043, 'output_tokens': 39, 'total_tokens': 3082, 'input_token_details': {'cache_read': 0}}\n",
      "\n",
      "ðŸ¤– Gemini:\n",
      "I am sorry, I am unable to answer your question based on the provided context. The context does not contain information about any specific event. Is there anything else I can help you with?\n",
      "content='I apologize, I do not have access to your name. As an AI, I do not retain information from previous conversations.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-lite', 'safety_ratings': []} id='run-294463cd-ebd8-4331-89d0-6df787ea29e3-0' usage_metadata={'input_tokens': 4007, 'output_tokens': 26, 'total_tokens': 4033, 'input_token_details': {'cache_read': 0}}\n",
      "\n",
      "ðŸ¤– Gemini:\n",
      "I apologize, I do not have access to your name. As an AI, I do not retain information from previous conversations.\n",
      "content='I am sorry, I do not have access to the previous questions you asked. As an AI, I do not retain information from previous conversations.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-lite', 'safety_ratings': []} id='run-013e8eff-a14a-4b86-a738-e45bffed6c48-0' usage_metadata={'input_tokens': 5142, 'output_tokens': 30, 'total_tokens': 5172, 'input_token_details': {'cache_read': 0}}\n",
      "\n",
      "ðŸ¤– Gemini:\n",
      "I am sorry, I do not have access to the previous questions you asked. As an AI, I do not retain information from previous conversations.\n",
      "content='I am sorry, I do not have enough information to answer your question. I can only provide information that is explicitly stated on the website. Is there anything else I can help you with?' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-lite', 'safety_ratings': []} id='run-7a049a3e-017f-43e0-b676-c3bef07e4867-0' usage_metadata={'input_tokens': 6271, 'output_tokens': 38, 'total_tokens': 6309, 'input_token_details': {'cache_read': 0}}\n",
      "\n",
      "ðŸ¤– Gemini:\n",
      "I am sorry, I do not have enough information to answer your question. I can only provide information that is explicitly stated on the website. Is there anything else I can help you with?\n",
      "ðŸ‘‹ Exiting chatbot. Have a great day!\n"
     ]
    }
   ],
   "source": [
    "state = {\"question\": \"\", \"answer\": None, \"docs\": None, \"first_turn\": True, \"chat_history\": []}\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        chatbot.invoke(state)\n",
    "    except SystemExit:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
