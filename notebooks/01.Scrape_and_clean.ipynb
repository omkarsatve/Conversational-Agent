{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One folder up from the current directory\n",
    "SAVE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"../data\"))\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "OUTPUT_FILE = os.path.join(SAVE_DIR, \"dxfactor_full_scrape.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_URL = \"https://dxfactor.com/\"\n",
    "WAIT_TIME = 5  # seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Setup Chrome in stealth mode ===\n",
    "driver = uc.Chrome(version_main=134, headless=True)\n",
    "driver.get(ROOT_URL)\n",
    "time.sleep(WAIT_TIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_current_page():\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "    content = []\n",
    "\n",
    "    # Only extract in-page tags in natural DOM order\n",
    "    for tag in soup.find_all([\"title\", \"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\",\"p\"]):\n",
    "        text = tag.get_text(strip=True)\n",
    "        if text and len(text) > 3:\n",
    "            content.append(text)\n",
    "\n",
    "    # Remove duplicates while keeping order\n",
    "    seen = set()\n",
    "    unique_content = []\n",
    "    for line in content:\n",
    "        if line not in seen:\n",
    "            seen.add(line)\n",
    "            unique_content.append(line)\n",
    "\n",
    "    return \"\\n\".join(unique_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Function: Extract first-level internal links ===\n",
    "def get_first_level_links():\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    links = set()\n",
    "    for a in soup.find_all(\"a\", href=True):\n",
    "        href = a[\"href\"]\n",
    "        if href.startswith(\"#\") or \"mailto:\" in href or \"tel:\" in href:\n",
    "            continue\n",
    "        full_url = urljoin(ROOT_URL, href)\n",
    "        if urlparse(full_url).netloc == urlparse(ROOT_URL).netloc:\n",
    "            links.add(full_url)\n",
    "    return list(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Scraping root page: https://dxfactor.com/\n",
      "[+] Collecting and scraping first-level links...\n",
      "  ✓ Scraped: https://dxfactor.com/ar-vr-solutions/\n",
      "  ✓ Scraped: https://dxfactor.com/case-studies/\n",
      "  ✓ Scraped: https://dxfactor.com/master-services-agreement/\n",
      "  ✓ Scraped: https://dxfactor.com/why-us/\n",
      "  ✓ Scraped: https://dxfactor.com/ebooks/\n",
      "  ✓ Scraped: https://dxfactor.com/testing-qa/\n",
      "  ✓ Scraped: https://dxfactor.com/data-visualization/\n",
      "  ✓ Scraped: https://dxfactor.com/about-us/\n",
      "  ✓ Scraped: https://dxfactor.com/fitgenai/#fittabst|0\n",
      "  ✓ Scraped: https://dxfactor.com/case-studies/ai-based-recommendation-engine-helps-a-global-information-services-company-increase-customer-retention-by-35-and-revenue-by-25/\n",
      "  ✓ Scraped: https://dxfactor.com/fitness-business-digital-services/\n",
      "  ✓ Scraped: https://dxfactor.com/data-science/\n",
      "  ✓ Scraped: https://dxfactor.com/web-app-development/\n",
      "  ✓ Scraped: https://dxfactor.com/iso-certification/\n",
      "  ✓ Scraped: https://dxfactor.com/mobile-application-development/\n",
      "  ✓ Scraped: https://dxfactor.com/webinars/\n",
      "  ✓ Scraped: https://dxfactor.com/contact-us/\n",
      "  ✓ Scraped: https://dxfactor.com/dxfactor-privacy-policy/\n",
      "  ✓ Scraped: https://dxfactor.com/manufacturing/\n",
      "  ✓ Scraped: https://dxfactor.com/fitgenai/#fittabst|2\n",
      "  ✓ Scraped: https://dxfactor.com/blockchain/\n",
      "  ✓ Scraped: https://dxfactor.com/transportation-logistics/\n",
      "  ✓ Scraped: https://dxfactor.com/cancellation-save-solution/\n",
      "  ✓ Scraped: https://dxfactor.com/fitgenai/\n",
      "  ✓ Scraped: https://dxfactor.com/case-studies/a-next-generation-data-solution-delivers-750000-savings-in-infrastructure-and-reconciliation-costs/\n",
      "  ✓ Scraped: https://dxfactor.com/blog/\n",
      "  ✓ Scraped: https://dxfactor.com/case-studies/learn-how-a-fortune-500-transportation-logistics-giant-reduced-their-data-costs-by-1000000-year/\n",
      "  ✓ Scraped: https://dxfactor.com/how-we-engage/\n",
      "  ✓ Scraped: https://dxfactor.com/fitgenai/#fittabst|3\n",
      "  ✓ Scraped: https://dxfactor.com/careers/\n",
      "  ✓ Scraped: https://dxfactor.com/data-engineering/\n",
      "  ✓ Scraped: https://dxfactor.com/fitgenai/#fittabst|1\n",
      "  ✓ Scraped: https://dxfactor.com/data-analytics/\n",
      "  ✓ Scraped: https://dxfactor.com/videos/\n",
      "  ✓ Scraped: https://dxfactor.com/api-and-system-integration/\n",
      "  ✓ Scraped: https://dxfactor.com/professional-services-agreement/\n",
      "  ✓ Scraped: https://dxfactor.com/machine-learning/\n",
      "  ✓ Scraped: https://dxfactor.com/news/\n",
      "  ✓ Scraped: https://dxfactor.com/terms-of-use/\n",
      "  ✓ Scraped: https://dxfactor.com/modern-data-platform/\n",
      "\n",
      "✅ Scraping complete. Saved to 'dxfactor_full_scrape.txt'\n"
     ]
    }
   ],
   "source": [
    "# === Scrape root page ===\n",
    "print(f\"[+] Scraping root page: {ROOT_URL}\")\n",
    "visited = set()\n",
    "all_data = []\n",
    "\n",
    "root_text = get_text_from_current_page()\n",
    "all_data.append((\"Home\", ROOT_URL, root_text))\n",
    "visited.add(ROOT_URL)\n",
    "\n",
    "# === Find and scrape first-level links ===\n",
    "print(\"[+] Collecting and scraping first-level links...\")\n",
    "first_level_links = get_first_level_links()\n",
    "\n",
    "for link in first_level_links:\n",
    "    if link in visited:\n",
    "        continue\n",
    "    try:\n",
    "        driver.get(link)\n",
    "        time.sleep(WAIT_TIME)\n",
    "        page_text = get_text_from_current_page()\n",
    "        title = link.rstrip(\"/\").split(\"/\")[-1].replace(\"-\", \" \").title()\n",
    "        if not title:\n",
    "            title = \"No Title\"\n",
    "        all_data.append((title, link, page_text))\n",
    "        visited.add(link)\n",
    "        print(f\"  ✓ Scraped: {link}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Failed: {link} — {e}\")\n",
    "\n",
    "# === Save results ===\n",
    "with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    for title, url, text in all_data:\n",
    "        f.write(f\"\\n\\n========== {title} ==========\\n\")\n",
    "        f.write(f\"URL: {url}\\n\\n\")\n",
    "        f.write(text)\n",
    "\n",
    "print(\"\\n✅ Scraping complete. Saved to 'dxfactor_full_scrape.txt'\")\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
